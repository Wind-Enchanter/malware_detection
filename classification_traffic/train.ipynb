{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.rcParams['font.size'] = 18\n",
    "matplotlib.rcParams['figure.titlesize'] = 18\n",
    "matplotlib.rcParams['figure.figsize'] = [9, 7]\n",
    "matplotlib.rcParams['font.family'] = ['KaiTi']\n",
    "matplotlib.rcParams['axes.unicode_minus']=False\n",
    "\n",
    "import  os\n",
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "from tensorflow.keras import layers, optimizers, Sequential, metrics\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')\n",
    "\n",
    "import sys\n",
    "sys.path.append('D:/USTC-TK2016/')\n",
    "from load_dataset import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    # x: 图片的路径，y：图片的数字编码\n",
    "    x = tf.io.read_file(x)\n",
    "    x = tf.image.decode_jpeg(x, channels=1) # RGBA\n",
    "    x = tf.image.resize(x, [28, 28])\n",
    "\n",
    "#     x = tf.image.random_flip_left_right(x)\n",
    "#     x = tf.image.random_flip_up_down(x)\n",
    "#     x = tf.image.random_crop(x, [224,224,3])\n",
    "\n",
    "    # x: [0,255]=> -1~1\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    y = tf.convert_to_tensor(y)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 1024\n",
    "# 创建训练集Datset对象\n",
    "images, labels, table = load_data('D:/USTC-TK2016/4_Png/testtest',mode='train')\n",
    "db_train = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "db_train = db_train.map(preprocess).batch(batchsz).repeat(10)\n",
    "# 创建验证集Datset对象\n",
    "images2, labels2, table = load_data('D:/USTC-TK2016/4_Png/testtest',mode='val')\n",
    "db_val = tf.data.Dataset.from_tensor_slices((images2, labels2))\n",
    "db_val = db_val.map(preprocess).batch(batchsz).repeat(10)\n",
    "# 创建测试集Datset对象\n",
    "images3, labels3, table = load_data('D:/USTC-TK2016/4_Png/testtest',mode='test')\n",
    "db_test = tf.data.Dataset.from_tensor_slices((images3, labels3))\n",
    "db_test = db_test.map(preprocess).batch(batchsz).repeat(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<RepeatDataset shapes: ((None, 28, 28, 1), (None, 10)), types: (tf.float32, tf.float32)>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            multiple                  832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            multiple                  51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  3212288   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  10250     \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "cnn_layers = [\n",
    "    layers.Conv2D(32, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "    layers.Conv2D(64, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu),\n",
    "    layers.MaxPool2D(pool_size=[2, 2], strides=2, padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation=tf.nn.relu),\n",
    "    layers.Dense(10, activation=tf.nn.softmax)\n",
    "]\n",
    "\n",
    "model = Sequential(cnn_layers)\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=keras.losses.CategoricalCrossentropy(), \n",
    "             metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "model.build(input_shape=(None, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `batch_size` argument must not be specified for the given input type. Received input: <RepeatDataset shapes: ((None, 28, 28, 1), (None, 10)), types: (tf.float32, tf.float32)>, batch_size: 32",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-38-29807445fa09>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdb_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdb_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m25\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[0mmax_queue_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    727\u001B[0m         \u001B[0mworkers\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 728\u001B[1;33m         use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[0;32m    729\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    730\u001B[0m   def evaluate(self,\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001B[0m\n\u001B[0;32m    195\u001B[0m       steps_per_epoch=None, validation_steps=None, validation_freq=1, **kwargs):\n\u001B[0;32m    196\u001B[0m     batch_size = model._validate_or_infer_batch_size(\n\u001B[1;32m--> 197\u001B[1;33m         batch_size, steps_per_epoch, x)\n\u001B[0m\u001B[0;32m    198\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    199\u001B[0m     \u001B[0mstrategy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_distribution_strategy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_validate_or_infer_batch_size\u001B[1;34m(self, batch_size, steps, x)\u001B[0m\n\u001B[0;32m   1815\u001B[0m             \u001B[1;34m'The `batch_size` argument must not be specified for the given '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1816\u001B[0m             'input type. Received input: {}, batch_size: {}'.format(\n\u001B[1;32m-> 1817\u001B[1;33m                 x, batch_size))\n\u001B[0m\u001B[0;32m   1818\u001B[0m       \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1819\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: The `batch_size` argument must not be specified for the given input type. Received input: <RepeatDataset shapes: ((None, 28, 28, 1), (None, 10)), types: (tf.float32, tf.float32)>, batch_size: 32"
     ]
    }
   ],
   "source": [
    "history = model.fit(db_train, epochs=4, steps_per_epoch=5, validation_data=db_val, validation_steps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# y_pred = model.predict_classes(db_test)\n",
    "# print(\"CNN_LSTM model classification report: \\n\\n {}\".format(classification_report(np.array(db_val), y_pred.flatten())))\n",
    "#\n",
    "# fig, ax = plt.subplots(1,2, figsize=[12,6])\n",
    "# ax[0].plot(history.history[\"loss\"])\n",
    "# ax[0].plot(history.history[\"val_loss\"])\n",
    "# ax[0].set_title(\" Loss\")\n",
    "# ax[0].legend((\"Training\", \"validation\"), loc=\"upper right\")\n",
    "# ax[0].set_xlabel(\"Epochs\")\n",
    "# ax[1].plot(history.history[\"categorical_accuracy\"])\n",
    "# ax[1].plot(history.history[\"val_categorical_accuracy\"])\n",
    "# ax[1].legend((\"Training\", \"validation\"), loc=\"lower right\")\n",
    "# ax[1].set_title(\"Accuracy\")\n",
    "# ax[1].set_xlabel(\"Epochs\")\n",
    "#\n",
    "# ax=skplt.metrics.plot_confusion_matrix(db_val, y_pred, figsize=(8, 7))\n",
    "# tickx=ax.set_xticklabels(['Benign', 'Malware'])\n",
    "# ticky=ax.set_yticklabels(['Benign', 'Malware'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(db_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}